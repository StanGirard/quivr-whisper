<!doctype html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Interaction WebApp</title>
    <script src="https://cdn.tailwindcss.com"></script>
</head>

<body class="bg-gray-100 flex items-center justify-center h-screen">
    <div id="app" class="text-center">
        <canvas id="audio-visualizer" width="640" height="100" class="bg-red-500 rounded-full cursor-pointer"></canvas>
        <audio id="audio-playback" controls class="hidden mt-4"></audio>
    </div>

    <script>
        let isRecording = false;
        let mediaRecorder;
        let audioChunks = [];
        let lastAudioLevel = 0;
        let silenceTimer;

        const audioVisualizer = document.getElementById('audio-visualizer');
        const audioPlayback = document.getElementById('audio-playback');
        const canvasCtx = audioVisualizer.getContext('2d');

        audioVisualizer.addEventListener('click', toggleRecording);

        let audioContext;
        let analyser;
        let dataArray;
        let bufferLength;

        function drawWaveform() {
            if (!analyser) return;

            requestAnimationFrame(drawWaveform);

            analyser.getByteTimeDomainData(dataArray);

            canvasCtx.fillStyle = 'rgb(255, 255, 255)';
            canvasCtx.fillRect(0, 0, audioVisualizer.width, audioVisualizer.height);

            canvasCtx.lineWidth = 2;
            canvasCtx.strokeStyle = 'rgb(0, 0, 0)';

            canvasCtx.beginPath();

            let sliceWidth = audioVisualizer.width * 1.0 / bufferLength;
            let x = 0;

            let sum = 0;

            for (let i = 0; i < bufferLength; i++) {
                let v = dataArray[i] / 128.0;
                let y = v * audioVisualizer.height / 2;

                sum += v;

                if (i === 0) {
                    canvasCtx.moveTo(x, y);
                } else {
                    canvasCtx.lineTo(x, y);
                }

                x += sliceWidth;
            }

            canvasCtx.lineTo(audioVisualizer.width, audioVisualizer.height / 2);
            canvasCtx.stroke();

            let currentAudioLevel = sum / bufferLength;

            if (isRecording && Math.abs(currentAudioLevel - lastAudioLevel) < 0.01) {
                if (!silenceTimer) {
                    silenceTimer = setTimeout(stopRecording, 1000);
                }
            } else {
                clearTimeout(silenceTimer);
                silenceTimer = null;
            }

            lastAudioLevel = currentAudioLevel;
        }

        async function toggleRecording() {
            if (!isRecording) {
                await startRecording();
            } else {
                stopRecording();
            }
        }

        async function startRecording() {
            audioChunks = [];
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorder = new MediaRecorder(stream);
            mediaRecorder.ondataavailable = event => {
                audioChunks.push(event.data);
            };
            mediaRecorder.start();
            isRecording = true;

            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            analyser = audioContext.createAnalyser();
            const source = audioContext.createMediaStreamSource(stream);

            source.connect(analyser);
            analyser.fftSize = 2048;
            bufferLength = analyser.frequencyBinCount;
            dataArray = new Uint8Array(bufferLength);

            drawWaveform();
        }

        function stopRecording() {
            mediaRecorder.stop();
            mediaRecorder.onstop = async () => {
                const audioBlob = new Blob(audioChunks);

                const formData = new FormData();
                formData.append('audio_data', audioBlob);
                const response = await fetch('/transcribe', {
                    method: 'POST',
                    body: formData
                });
                const data = await response.json();
                audioPlayback.src = 'data:audio/wav;base64,' + data.audio_base64;
                audioPlayback.classList.remove('hidden');

                // Prepare to visualize AI response
                setupAIResponseVisualization();

                audioPlayback.onloadedmetadata = () => {
                    // When metadata is loaded, start playback and visualization
                    audioPlayback.play();
                    visualizeAIResponse();
                };

                isRecording = false;

                if (analyser) {
                    analyser.disconnect();
                    analyser = null;
                }
            };
        }

        function setupAIResponseVisualization() {
            try {
                // Create a new audio context for playback if it doesn't exist
                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                }
                // Resume the audio context in case it's in a suspended state
                audioContext.resume().then(() => {
                    analyser = audioContext.createAnalyser();
                    const source = audioContext.createMediaElementSource(audioPlayback);
                    source.connect(analyser);
                    analyser.connect(audioContext.destination);
                    analyser.fftSize = 2048;
                    bufferLength = analyser.frequencyBinCount;
                    dataArray = new Uint8Array(bufferLength);
                });
            } catch (error) {
                console.error('Error setting up AI response visualization:', error);
            }
        }

        function visualizeAIResponse() {
            const draw = () => {
                requestAnimationFrame(draw);

                analyser.getByteTimeDomainData(dataArray);

                canvasCtx.fillStyle = 'rgb(255, 255, 255)';
                canvasCtx.fillRect(0, 0, audioVisualizer.width, audioVisualizer.height);

                canvasCtx.lineWidth = 2;
                canvasCtx.strokeStyle = 'rgb(0, 0, 0)';

                canvasCtx.beginPath();

                let sliceWidth = audioVisualizer.width * 1.0 / bufferLength;
                let x = 0;

                for (let i = 0; i < bufferLength; i++) {
                    let v = dataArray[i] / 128.0;
                    let y = v * audioVisualizer.height / 2;

                    if (i === 0) {
                        canvasCtx.moveTo(x, y);
                    } else {
                        canvasCtx.lineTo(x, y);
                    }

                    x += sliceWidth;
                }

                canvasCtx.lineTo(audioVisualizer.width, audioVisualizer.height / 2);
                canvasCtx.stroke();
            };

            draw();
        }

    </script>
</body>

</html>